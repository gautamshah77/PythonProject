{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DOTA2 Team Prediction Model using machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dota2 by Valve is a popular computer game with a player base of 10 million unique users. Each Dota 2 match consists of two teams of five players pitted against each other. Before a match begins, each player selects a character to play as, known as a “hero,” from a pool of 113 different heroes. Once a player chooses a hero, no other player can select that hero for the same match. Heroes have a wide-range of characteristics and abilities that, combined with the massive hero pool, make each match unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting aspect of the game is that in choosing a hero, players must keep in mind not only the individual strengths and weaknesses of each hero, but also how the strengths and weaknesses of that hero interacts with the heroes already chosen by other players. An effective hero pick is one that synergizes with the heroes chosen by teammates, and both exploits the weaknesses and minimizes the strengths of the heroes chosen by the opposing team. Assuming equally skilled teams, the ramifications of hero selection can be so staggering that well devised hero choices can implicitly give a team a large advantage before the match even begins. The goal of our project is to recommend heroes that will perform well against an opposing team of heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 113 heroes to choose from and five heroes per team, we are attempting to find the best five heroes for any given matchup, which results in over eight quadrillion possible team combinations. On a deeper level, recommending heroes using machine learning is challenging because it tries to capture via raw data what professional players have developed a gut instinct for through hundreds of thousands of hours of play time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data satisfies the following requirements: \u000f The game mode is either all pick, single draft, all random, random draft, captain’s draft, captain’s mode, or least played. These game modes are the closest to the true vision of Dota 2. \u000f We pulled 8000 records from the API out of which only unique records are used to create a database in MongoDB. The data for each match is structured as JSON and includes which heroes were chosen for each team, how those heroes performed over the course of the game, and which team ultimately won the game. We exported 90% of the matches from our database to form a training set. The remaining 10% of our database was used to form a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Data from Steam Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data using Dota2API provided by Steam in JSON format, and then creating a MongoDB database using the results. Since, there is a limit to the number of match details that can be pulled from the game client, we have used a try-catch block to avoid disruption of our code due to the API limit. Each request pulls data for 100 matches. We have implemented a while loop to pull data for 8000 matches in all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dota2API is an open source library of functions provided by Steam (Valve Corporation). To install this api, use: pip install dota2api. The web link for the same is found at: https://dota2api.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dota2api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise the API using a Steam account token key\n",
    "api = dota2api.Initialise(\"C4478A705AA9040E7660A53B0DD61092\")\n",
    "count = 0\n",
    "docs = []\n",
    "i = 2639900000 #Choose a random match sequence number to begin pulling the data\n",
    "while count<=8000:  \n",
    "    try:\n",
    "      matchData = api.get_match_history_by_seq_num(start_at_match_seq_num=i)\n",
    "      docs = docs + matchData[\"matches\"]\n",
    "      count += len(matchData[\"matches\"])      \n",
    "    except :\n",
    "        pass\n",
    "        #print(\"Api limit exception error occured,retrying next set of data\")\n",
    "    finally:\n",
    "        i += 100\n",
    "print(\"Data downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed to add the pulled data into a MongoDB database. To avoid duplicate entries, we again employ a try-catch block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "con=MongoClient()\n",
    "DotaDB=con.Dota\n",
    "matches=DotaDB.NewMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coll = []\n",
    "for j in docs:           \n",
    "        j['_id'] = j[\"match_id\"]\n",
    "        coll.append(j)\n",
    "try:\n",
    "   matches.insert_many(coll, ordered=False)\n",
    "except:\n",
    "    print(\"Records inserted,duplicate matches details ignored\")\n",
    "finally:\n",
    "    print(\"Total Records inserted\", matches.find().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample match data:' + coll[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Applying Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "import pymongo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "connection = pymongo.MongoClient(\"mongodb://localhost\")\n",
    "\n",
    "DotaDB = connection.Dota\n",
    "matches = DotaDB.NewMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold = np.nan)\n",
    "NUM_HEROES = 114\n",
    "NUM_FEATURES = NUM_HEROES * 2\n",
    "NUM_MATCHES = matches.count()\n",
    "\n",
    "# Initialize training matrix\n",
    "X = np.zeros((NUM_MATCHES, NUM_FEATURES), dtype = np.int8)\n",
    "\n",
    "# Initialize training label vector\n",
    "Y = np.zeros(NUM_MATCHES, dtype = np.int8)\n",
    "\n",
    "\n",
    "for i, record in enumerate(matches.find()):    \n",
    "    Y[i] = 1 if record['radiant_win'] else 0\n",
    "    players = record['players']\n",
    "    for player in players:\n",
    "        hero_id = player['hero_id'] - 1               \n",
    "        player_slot = player['player_slot']\n",
    "        if player_slot >= 128:\n",
    "            hero_id += NUM_HEROES\n",
    "        X[i, hero_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.random.permutation(NUM_MATCHES)\n",
    "test_indices = indices[0:NUM_MATCHES/10]\n",
    "train_indices = indices[NUM_MATCHES/10:NUM_MATCHES]\n",
    "\n",
    "X_test = X[test_indices]\n",
    "Y_test = Y[test_indices]\n",
    "X_train = X[train_indices]\n",
    "Y_train = Y[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample Train data: ' + X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = len(X_train)\n",
    "model = LogisticRegression().fit(X_train[0:num_samples], Y_train[0:num_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateMatrix(my_team, their_team):\n",
    "        X = np.zeros(NUM_FEATURES, dtype=np.int8)\n",
    "        for hero_id in my_team:\n",
    "            X[hero_id] = 1\n",
    "        for hero_id in their_team:\n",
    "            X[hero_id] = 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(query,model):\n",
    "        radiant_query = query\n",
    "        dire_query = np.concatenate((radiant_query[NUM_HEROES:NUM_FEATURES], radiant_query[0:NUM_HEROES]))\n",
    "        rad_prob = model.predict_proba(radiant_query)[0][1]\n",
    "        dire_prob = model.predict_proba(dire_query)[0][0]\n",
    "        return (rad_prob + dire_prob) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying model on test dataset \n",
    "prediction = []\n",
    "for i in range(len(X_test)):\n",
    "    list1 = predict(X_test[i],model)   \n",
    "    prediction.append((list1,Y_test[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Prediction for each match: ' + prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a graph to depict the test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X, Y,positive_class, negative_class):    \n",
    "    correct_predictions = 0.0\n",
    "    for i, radiant_query in enumerate(X):\n",
    "        overall_prob = predict(radiant_query,model)\n",
    "        prediction = positive_class if (overall_prob > 0.5) else negative_class\n",
    "        result = 1 if prediction == Y[i] else 0\n",
    "        correct_predictions += result\n",
    "    return correct_predictions/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_accuracy(X_test, Y_test):\n",
    "    test_error = evaluateModel(model, X_test, Y_test, 1, 0) \n",
    "    plt.bar (1,test_error,width=0.2,align='center')    \n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.title('Logistic Regression Model Efficiency')\n",
    "    frame = plt.gca()    \n",
    "    frame.axes.get_xaxis().set_visible(False)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model_accuracy(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHeroList(data):\n",
    "    radiant_list = []\n",
    "    dire_list = []\n",
    "    for i in range(NUM_FEATURES):\n",
    "        if data[i] == 1 and i < NUM_HEROES:\n",
    "            radiant_list.append(i)\n",
    "        elif data[i] == 1 and i >= NUM_HEROES:\n",
    "            dire_list.append(i)          \n",
    "    return radiant_list,dire_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample Radiant and Dire Team List: ' + getHeroList(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendation(data):\n",
    "    rad_team,dire_team = getHeroList(data)\n",
    "    hero_candidates = np.arange(0,113)\n",
    "    hero_candidates.reshape(1,-1)\n",
    "    probs = recommend(rad_team,dire_team,hero_candidates)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample probablity: ' + get_recommendation(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend(my_team, their_team, hero_candidates):\n",
    "        my_team.pop()\n",
    "        team_possibilities = [(candidate, my_team + [candidate]) for candidate in hero_candidates]\n",
    "        prob_candidate_pairs = []\n",
    "        for candidate, team in team_possibilities:\n",
    "            query = generateMatrix(team, their_team)\n",
    "            prob = predict(query,model) \n",
    "            prob_candidate_pairs.append((prob, candidate))        \n",
    "        return prob_candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building recommendation matrix \n",
    "recommendations = []    \n",
    "for i in range(len(X_test)):\n",
    "    pr = get_recommendation(X_test[i])\n",
    "    recommendations.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample Recommendation: ' + recommendations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test[25].reshape(1,-1)\n",
    "recommend_list = get_recommendation(X_test[25])\n",
    "recommend_list.sort(reverse=True)\n",
    "topFifteen = recommend_list[:15]\n",
    "values = dict(topFifteen)\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(range(len(values)), values.keys(), width = 0.2, color = 'r', align = 'center') \n",
    "plt.xticks(range(len(values)),values.values())\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Hero Id')\n",
    "#plt.legend()\n",
    "plt.title('Recommedation Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hero wise Data Analysis\n",
    "\n",
    "herocount = [0] * 115\n",
    "kills = [0] * 115\n",
    "deaths = [0] * 115\n",
    "assists = [0] * 115\n",
    "for i in matches.find():\n",
    "    for j in i[\"players\"]:    \n",
    "        herocount[j[\"hero_id\"]]+=1\n",
    "        kills[j[\"hero_id\"]]+=j[\"kills\"]\n",
    "        deaths[j[\"hero_id\"]]+=j[\"deaths\"]\n",
    "        assists[j[\"hero_id\"]]+=j[\"assists\"]\n",
    "maxpick = max(herocount)\n",
    "mostPickedHeroID = herocount.index(maxpick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The most picked hero is \", mostPickedHeroID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kda = {}\n",
    "for i in range(len(kills)):\n",
    "    num = kills[i]+assists[i]\n",
    "    den = deaths[i]\n",
    "    if den !=0:\n",
    "        kda.update({i:num/den})\n",
    "    else:\n",
    "         kda.update({i:num})\n",
    "\n",
    "sorted_kda=sorted(kda.items(),key=itemgetter(1),reverse=True)\n",
    "values={}\n",
    "for i in range(10):\n",
    "   values.update({sorted_kda[i][0]:sorted_kda[i][1]})\n",
    "\n",
    "highestImpact=sorted_kda[0][1]\n",
    "HighestImpactHeroID=sorted_kda[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The hero with best impact ratio: \", HighestImpactHeroID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top 10 heros with the highest impact:\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(range(len(values)),values.values() , width=0.2,color='g', align='center') \n",
    "plt.xticks(range(len(values)),values.keys())\n",
    "\n",
    "ax.set_ylabel('KDA')\n",
    "ax.set_xlabel('Hero Id')\n",
    "plt.title('Top Ten Impact Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions and Further Expansions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using data to recommend how substituting any hero of a particular team would change the probablity to winning the game. We are also finding out facts such as: most played hero, hero with the highest impact in terms of getting kills and assists.\n",
    "\n",
    "Further, expansion can be an inclusion of analysis on the other factors (i.e hero properties like experience per minute, gold per minute, denies, barrack status and tower status) and how the players synergize with each other. Also doing the analysis only on the top players would result into a better model since the top players will be able to make full use of the hero capabilities. \n",
    "We are just using 6000 records to form the model whereas the actual dataset that we were able to pull was around 1.5 lakhs which would improve the model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

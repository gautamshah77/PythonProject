{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DOTA2 Team Prediction Model using machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dota2 by Valve is a popular computer game with a player base of 6 million unique users. Each Dota 2 match consists of two teams of five players pitted against each other. Before a match begins, each player selects a character to play as, known as a “hero,” from a pool of 113 different heroes. Once a player chooses a hero, no other player can select that hero for the same match. Heroes have a wide-range of characteristics and abilities that, combined with the massive hero pool, make each match unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting aspect of the game is that in choosing a hero, players must keep in mind not only the individual strengths and weaknesses of each hero, but also how the strengths and weaknesses of that hero interacts with the heroes already chosen by other players. An effective hero pick is one that synergizes with the heroes chosen by teammates, and both exploits the weaknesses and minimizes the strengths of the heroes chosen by the opposing team. Assuming equally skilled teams, the ramifications of hero selection can be so staggering that well devised hero choices can implicitly give a team a large advantage before the match even begins. The goal of our project is to recommend heroes that will perform well against an opposing team of heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 113 heroes to choose from and five heroes per team, we are attempting to find the best five heroes for any given matchup, which results in over eight quadrillion possible team combinations. On a deeper level, recommending heroes using machine learning is challenging because it tries to capture via raw data what professional players have developed a gut instinct for through hundreds of thousands of hours of play time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data satisfies the following requirements: \u000f The game mode is either all pick, single draft, all random, random draft, captain’s draft, captain’s mode, or least played. These game modes are the closest to the true vision of Dota 2. \u000f We pulled 8000 records from the API out of which 5923 records were unique which were then used to create a database in MongoDB. The data for each match is structured as JSON and includes which heroes were chosen for each team, how those heroes performed over the course of the game, and which team ultimately won the game. We exported 90% of the matches from our database to form a training set. The remaining 10% of our database was used to form a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Data from Steam Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data using Dota2API provided by Steam in JSON format, and then creating a MongoDB database using the results. Since, there is a limit to the number of match details that can be pulled from the game client, we have used a try-catch block to avoid disruption of our code due to the API limit. Each request pulls data for 100 matches. We have implemented a while loop to pull data for 8000 matches in all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dota2api\n",
    "\n",
    "#Initialise the API using a Steam account token key\n",
    "api = dota2api.Initialise(\"C4478A705AA9040E7660A53B0DD61092\")\n",
    "count = 0\n",
    "docs = []\n",
    "i = 2639900000 #Choose a random match sequence number to begin pulling the data\n",
    "while count<=8000:  \n",
    "    try:\n",
    "      matchData = api.get_match_history_by_seq_num(start_at_match_seq_num=i)\n",
    "      docs = docs + matchData[\"matches\"]\n",
    "      count += len(matchData[\"matches\"])      \n",
    "    except :\n",
    "        print(\"Api limit exception error occured,retrying next set of data\")\n",
    "    finally:\n",
    "        i += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed to add the pulled data into a MongoDB database. To avoid duplicate entries, we again employ a try-catch block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "con=MongoClient()\n",
    "DotaDB=con.Dota\n",
    "matches=DotaDB.NewMatches\n",
    "coll = []\n",
    "for j in docs:           \n",
    "        j['_id'] = j[\"match_id\"]\n",
    "        coll.append(j)\n",
    "try:\n",
    "   matches.insert_many(coll, ordered=False)\n",
    "except:\n",
    "    print(\"Records inserted,duplicate matches details ignored\")\n",
    "finally:\n",
    "    print(\"Total Records inserted\", matches.find().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hero wise Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "herocount = [0] * 115\n",
    "kills = [0] * 115\n",
    "deaths = [0] * 115\n",
    "assists = [0] * 115\n",
    "\n",
    "for i in matches.find():\n",
    "    for j in i[\"players\"]:    \n",
    "        herocount[j[\"hero_id\"]] += 1\n",
    "        kills[j[\"hero_id\"]] += j[\"kills\"]\n",
    "        deaths[j[\"hero_id\"]] += j[\"deaths\"]\n",
    "        assists[j[\"hero_id\"]] += j[\"assists\"]\n",
    "        \n",
    "maxpick = max(herocount)\n",
    "mostPickedHeroID = herocount.index(maxpick)\n",
    "\n",
    "#Kill Death Assist Ratio:\n",
    "kda = [0] * 115\n",
    "for i in range(len(kills)):\n",
    "    num = kills[i] + assists[i]\n",
    "    den = deaths[i]\n",
    "    if den != 0:\n",
    "        kda[i] = num/den\n",
    "    else:\n",
    "        kda[i] = num\n",
    "\n",
    "#Player having the highest Kill Death Assist Ratio has the Highest Impact in the game\n",
    "highestImpact = max(kda)\n",
    "HighestImpactHeroID = kda.index(highestImpact)\n",
    "\n",
    "print(\"The most picked hero is \", mostPickedHeroID)\n",
    "print(\"The hero with best impact ratio\", HighestImpactHeroID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Applying logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from bson.code import Code\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "connection = pymongo.MongoClient(\"mongodb://localhost\")\n",
    "\n",
    "DotaDB = connection.Dota\n",
    "matches = DotaDB.NewMatch1\n",
    "np.set_printoptions(threshold = np.nan)\n",
    "NUM_HEROES = 114\n",
    "NUM_FEATURES = NUM_HEROES * 2\n",
    "NUM_MATCHES = matches.count()\n",
    "\n",
    "# Initialize training matrix\n",
    "X = np.zeros((NUM_MATCHES, NUM_FEATURES), dtype = np.int8)\n",
    "\n",
    "# Initialize training label vector\n",
    "Y = np.zeros(NUM_MATCHES, dtype = np.int8)\n",
    "\n",
    "\n",
    "for i, record in enumerate(matches.find()):    \n",
    "    Y[i] = 1 if record['radiant_win'] else 0\n",
    "    players = record['players']\n",
    "    for player in players:\n",
    "        hero_id = player['hero_id'] - 1               \n",
    "        player_slot = player['player_slot']\n",
    "        if player_slot >= 128:\n",
    "            hero_id += NUM_HEROES\n",
    "        X[i, hero_id] = 1\n",
    "        \n",
    "\n",
    "\n",
    "indices = np.random.permutation(NUM_MATCHES)\n",
    "test_indices = indices[0:NUM_MATCHES/10]\n",
    "train_indices = indices[NUM_MATCHES/10:NUM_MATCHES]\n",
    "\n",
    "\n",
    "X_test = X[test_indices]\n",
    "Y_test = Y[test_indices]\n",
    "X_train = X[train_indices]\n",
    "Y_train = Y[train_indices]\n",
    "\n",
    "num_samples = len(X_train)\n",
    "model = LogisticRegression().fit(X_train[0:num_samples], Y_train[0:num_samples])\n",
    "\n",
    "\n",
    "def generateMatrix(my_team, their_team):\n",
    "        X = np.zeros(NUM_FEATURES, dtype=np.int8)\n",
    "        for hero_id in my_team:\n",
    "            X[hero_id] = 1\n",
    "        for hero_id in their_team:\n",
    "            X[hero_id] = 1\n",
    "        return X\n",
    "\n",
    "    \n",
    "def getProbability(query,model):\n",
    "        radiant_query = query\n",
    "        dire_query = np.concatenate((radiant_query[NUM_HEROES:NUM_FEATURES], radiant_query[0:NUM_HEROES]))\n",
    "        rad_prob = model.predict_proba(radiant_query)[0][1]\n",
    "        dire_prob = model.predict_proba(dire_query)[0][0]\n",
    "        return (rad_prob + dire_prob) / 2\n",
    "\n",
    "def predict(dream_team_query,model):        \n",
    "        return getProbability(dream_team_query,model)    \n",
    "\n",
    "\n",
    "def getHeroList(data):\n",
    "    radiant_list = []\n",
    "    dire_list = []\n",
    "    for i in range(NUM_FEATURES):\n",
    "        if data[i] == 1 and i < NUM_HEROES:\n",
    "            radiant_list.append(i)\n",
    "        elif data[i] == 1 and i >= NUM_HEROES:\n",
    "            dire_list.append(i)          \n",
    "    return radiant_list,dire_list            \n",
    "\n",
    "def get_recommendation(data):\n",
    "    rad_team,dire_team = getHeroList(data)\n",
    "    hero_candidates = np.arange(0,113)\n",
    "    hero_candidates.reshape(1,-1)\n",
    "    probs = recommend(rad_team,dire_team,hero_candidates)\n",
    "    return probs\n",
    "    \n",
    "def recommend(my_team, their_team, hero_candidates):\n",
    "        team_possibilities = [(candidate, my_team + [candidate]) for candidate in hero_candidates]\n",
    "        prob_candidate_pairs = []\n",
    "        for candidate, team in team_possibilities:\n",
    "            query = generateMatrix(team, their_team)\n",
    "            prob = getProbability(query,model) \n",
    "            prob_candidate_pairs.append((prob, candidate))        \n",
    "        return prob_candidate_pairs\n",
    "    \n",
    "#Applying model on test dataset \n",
    "prediction = []\n",
    "for i in range(len(X_test)):\n",
    "    list1 = predict(X_test[i],model)   \n",
    "    prediction.append((list1,Y_test[i])) \n",
    "\n",
    "#building recommendation matrix \n",
    "recommendations = []    \n",
    "for i in range(len(X_test)):\n",
    "    pr = get_recommendation(X_test[i])\n",
    "    recommendations.append(pr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generating a graph to depict the Test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, positive_class, negative_class):    \n",
    "    correct_predictions = 0.0\n",
    "    for i, radiant_query in enumerate(X):\n",
    "        overall_prob = getProbability(radiant_query,model)\n",
    "        prediction = positive_class if (overall_prob > 0.5) else negative_class\n",
    "        result = 1 if prediction == Y[i] else 0\n",
    "        correct_predictions += result\n",
    "\n",
    "    return correct_predictions/len(X)\n",
    "\n",
    "    \n",
    "test_error = evaluate(model, X_test, Y_test, 1, 0)\n",
    "def plot_learning_curve(num_points, X_train, Y_train, X_test, Y_test, positive_class=1, negative_class=0):\n",
    "    total_num_matches = len(X_train)\n",
    "    training_set_sizes = []\n",
    "    for div in list(reversed(range(1, num_points + 1))):\n",
    "        training_set_sizes.append(total_num_matches / div)\n",
    "        \n",
    "    accuracies = []\n",
    "    tr_size = []\n",
    "    test_errors = []\n",
    "    for training_set_size in training_set_sizes:\n",
    "        if(training_set_size > 2):      \n",
    "            model = LogisticRegression().fit(X_train[0:training_set_size],Y_train[0:training_set_size])        \n",
    "            accuracy = evaluate(model, X_train, Y_train, positive_class, negative_class)\n",
    "            test_error = evaluate(model, X_test, Y_test, positive_class, negative_class)\n",
    "            test_errors.append(test_error)\n",
    "            accuracies.append(accuracy)\n",
    "            tr_size.append(training_set_size)\n",
    "    plt.plot(np.array(tr_size), np.array(accuracies))\n",
    "    plt.plot(tr_size, test_errors, 'g^-', label='Test accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Number of training samples')\n",
    "    plt.title('Logistic Regression Learning Curve')\n",
    "    pylab.show()\n",
    "    \n",
    "\n",
    "plot_learning_curve(100,X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommend_list=get_recommendation(X_test[0])\n",
    "recommend_list.sort(reverse=True)\n",
    "topFifteen=v[1:15]\n",
    "values=dict(topFifteen)\n",
    "\n",
    "print(values)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(range(len(values)), values.keys(), width=0.2,color='r', align='center',label=\"Probab.\") \n",
    "plt.xticks(range(len(values)),values.values())\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Hero Id')\n",
    "plt.legend()\n",
    "plt.title('Recommedation Probability')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
